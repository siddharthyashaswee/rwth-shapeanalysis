{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Point-based Learning Methods\n",
    "For this exercise you will implement the PointNet architecture as well as you will implement a point-based convolution method.\n",
    "\n",
    "To create a dataset of point clouds you need Open3D. This can be installed via `conda install open3d`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import openmesh as om\n",
    "import numpy as np\n",
    "import k3d\n",
    "import matplotlib.pyplot as plt\n",
    "from jupyterplot import ProgressPlot\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.neighbors import KDTree\n",
    "\n",
    "from dataset import ModelNet10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PointNet\n",
    "The PointNet architecture you will implement in this exercise is a slightly simplified version of the one presented in the lecture. We will omit the T-Net modules for point and feature alignment.\n",
    "Your task is therefore to implement a network, that transforms each point of a point cloud individually. and then take the maximum of each feature value over all points. The number of layers and layer parameters should be the same as presented in the lecture.\n",
    "\n",
    "We will test your PointNet implementation on the ModelNet10 dataset. We will first need to download the dataset and as it contains meshes, sample it as well. This will take a couple of minutes.\n",
    "\n",
    "Make sure to upload your `best_val.ckpt` checkpoint file so that we do not have to retrain your model. If the file is not included we **cannot** give you any points for this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-d4a666afc6661622",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class PointNet(nn.Module):\n",
    "    def __init__(self, n_classes=10):\n",
    "        super().__init__()\n",
    "\n",
    "        ### BEGIN SOLUTION\n",
    "        self.local = nn.Sequential(\n",
    "            nn.Conv1d(3,64,1, bias=False), # b x 3 x n\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(64,64,1, bias=False),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(64,64,1, bias=False),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(64,128,1, bias=False),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(128,1024,1, bias=False),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.ReLU() # b x 1024 x n\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(1024, 512, bias=False),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 256, bias=False),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, n_classes),\n",
    "        )\n",
    "        ### END SOLUTION\n",
    "\n",
    "    def forward(self, x):\n",
    "        ### BEGIN SOLUTION\n",
    "        x = self.local(x)\n",
    "        x = torch.max(x, dim=2)[0]\n",
    "        x = self.classifier(x)\n",
    "        ### END SOLUTION\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64 # you can change the batch size depending on your memory requirements\n",
    "train_data = ModelNet10('./ModelNet10', mode=\"train\")\n",
    "val_data = ModelNet10('./ModelNet10', mode=\"val\")\n",
    "test_data = ModelNet10('./ModelNet10', mode=\"test\")\n",
    "train_loader = torch.utils.data.DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
    "val_loader = torch.utils.data.DataLoader(val_data, shuffle=False, batch_size=batch_size)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, shuffle=False, batch_size=batch_size)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    \n",
    "model = PointNet(10).to(device)\n",
    "optim = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 10\n",
    "\n",
    "pp = ProgressPlot(plot_names=[\"loss\", \"accuracy\"], line_names=[\"train\", \"val\"],\n",
    "                  x_lim=[0, n_epochs-1], y_lim=[[0,1], [0,1]])\n",
    "\n",
    "best_val_acc = -1\n",
    "\n",
    "pbar = tqdm(range(n_epochs))\n",
    "for e in pbar:\n",
    "    train_loss = 0\n",
    "    train_acc = 0\n",
    "    model.train()\n",
    "    for (x,y) in train_loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        pred = model(x)\n",
    "        loss = F.cross_entropy(pred, y)\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        train_loss += loss.item()\n",
    "        train_acc += (pred.max(-1).indices == y).float().sum().item()\n",
    "    train_loss /= len(train_loader)\n",
    "    train_acc /= len(train_data)\n",
    "    \n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    val_acc = 0\n",
    "    with torch.no_grad():\n",
    "        for (x,y) in val_loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            pred = model(x)\n",
    "            loss = F.cross_entropy(pred, y)\n",
    "            val_loss += loss.item()\n",
    "            val_acc += (pred.max(-1).indices == y).float().sum().item()\n",
    "        val_loss /= len(val_loader)\n",
    "        val_acc /= len(val_data)\n",
    "        if val_acc > best_val_acc:\n",
    "            torch.save({\n",
    "            'epoch': e,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optim_state_dict': optim.state_dict(),\n",
    "            'val_acc': val_acc,\n",
    "            }, \"best_val.ckpt\")\n",
    "    \n",
    "    pp.update([[train_loss, val_loss], [train_acc, val_acc]])\n",
    "    pbar.set_description(f\"train loss: {train_loss:.4f}, train acc.: {train_acc:.4f}\")\n",
    "pp.finalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-2a733f240a6dade1",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "checkpoint = torch.load(\"best_val.ckpt\")\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval()\n",
    "test_acc = 0\n",
    "with torch.no_grad():\n",
    "    for (x,y) in tqdm(test_loader):\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            pred = model(x)\n",
    "            test_acc += (pred.max(-1).indices == y).float().sum().item()\n",
    "test_acc /= len(test_data)\n",
    "print(f\"test acc.: {test_acc}\")\n",
    "assert test_acc >= 0.7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Point Convolutions\n",
    "In this exercise you will implement point convolutions as presented in the lecture.\n",
    "For this you need to implement three functions:\n",
    "\n",
    "- `neighbourhood(self, points)` should return the indices of the `self.n_neighbours` closest points to each sample point. The output should be of size (n_points, n_neighbours)\n",
    "- `correlation(self, positions, neighbours)` should implement the (linear) distance based point correlation as described in slide 28 of \"Point based Approaches\". The output should be of size (n_points, n_kernel_points, n_neighbours). [Here](./correlation.html) you can see the nearest neighbours, kernel points and correlation for a specific vertex.\n",
    "- `forward(self, features, points)` implements the complete PointConvolution, using the previous functions. It should return a tensor of size (out_channel, n_points). The result should look like [this](./result.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-caa0f920489a5684",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def meshgrid(s, device=torch.device('cpu')):\n",
    "    r = torch.arange(s, device=device, dtype=torch.float)\n",
    "    x = r[:, None, None].expand(s, s, s)\n",
    "    y = r[None, :, None].expand(s, s, s)\n",
    "    z = r[None, None, :].expand(s, s, s)\n",
    "    return torch.stack([x, y, z], 0) / (s - 1) - 0.5\n",
    "\n",
    "class PointConvolution(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, n_neighbours=30):\n",
    "        super().__init__()\n",
    "\n",
    "        self.kernel_size = kernel_size\n",
    "        self.n_neighbours = n_neighbours\n",
    "        self.kernel_radius = 0.1\n",
    "        self.sigma = 0.2\n",
    "        self.kernel_points = meshgrid(self.kernel_size).view(3,-1) * self.kernel_radius\n",
    "        \n",
    "        # in practice we would initialize the weights randomly\n",
    "        self.weights = nn.Parameter(torch.ones((self.kernel_size**3, in_channels, out_channels), \n",
    "                                               dtype=torch.float32))\n",
    "        \n",
    "        \n",
    "    def neighbourhood(self, points):\n",
    "        ### BEGIN SOLUTION\n",
    "        tree = KDTree(points.transpose(1,0)) \n",
    "        neighbours = tree.query(points.transpose(1,0), k=self.n_neighbours)\n",
    "        return neighbours[1]\n",
    "        ### END SOLUTION\n",
    "        \n",
    "    def correlation(self, positions, neighbours):\n",
    "        ### BEGIN SOLUTION\n",
    "        relative = neighbours - positions.unsqueeze(-1).repeat([1,1,self.n_neighbours]) #3, n, m\n",
    "        differences = relative[:,:,:,None] - self.kernel_points[:,None,None,:] #3, n, m, k\n",
    "        distances = torch.norm(differences, dim=0) #n, m, k\n",
    "        correlation = torch.clamp(1 - distances / self.sigma, min=0.0)\n",
    "        correlation = correlation.transpose(1, 2) #n, k, m\n",
    "        return correlation\n",
    "        ### END SOLUTION\n",
    "\n",
    "    def forward(self, features, points):\n",
    "        ### BEGIN SOLUTION\n",
    "        # compute neighbourhood (should return indices)\n",
    "        neighbour_indices = self.neighbourhood(points)\n",
    "        neighbour_points = points[:, neighbour_indices]\n",
    "        neighbour_features = features[:, neighbour_indices].permute(1,2,0) # [n_points, n_neighbours, in_channels]\n",
    "        \n",
    "        # compute correlation [n_points, n_kernel_points, n_neighbours]\n",
    "        h = self.correlation(points, neighbour_points)\n",
    "        \n",
    "        # Apply distance weights [n_points, n_kernel_points, in_channels]\n",
    "        weighted_features = torch.bmm(h, neighbour_features)\n",
    "\n",
    "        # Apply network weights [n_kernel_points, n_points, out_channels]\n",
    "        weighted_features = weighted_features.permute((1, 0, 2)) # [n_kernel_points, n_points, in_channels]\n",
    "        kernel_outputs = torch.matmul(weighted_features, self.weights) # [n_kernel_points, in_channels, out_channels]\n",
    "\n",
    "        # Convolution sum [out_channels, n_points]\n",
    "        return torch.sum(kernel_outputs, dim=0).transpose(1,0)\n",
    "        ### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-108b250966091b5a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "mesh = om.read_trimesh(\"spot.obj\")\n",
    "pts = torch.from_numpy(mesh.points()).float().transpose(1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "216 ms ± 3.47 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "conv = PointConvolution(8,16, n_neighbours=30)\n",
    "f = conv(torch.ones(8,2930), pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-5f1d5a45c3ca86c6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "conv = PointConvolution(1,1, n_neighbours=50)\n",
    "neighbours = conv.neighbourhood(pts)\n",
    "neighbour_points = pts[:, neighbours]\n",
    "h = conv.correlation(pts, neighbour_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-eb79cb133a207406",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "colors = torch.zeros(pts.shape[1])\n",
    "colors[neighbours[0]] = h[0,13]\n",
    "plot = k3d.plot()\n",
    "plot += k3d.mesh(mesh.points(), mesh.fv_indices(), attribute=colors, \n",
    "                 color_map=k3d.colormaps.matplotlib_color_maps.viridis)\n",
    "plot += k3d.points(conv.kernel_points.transpose(0,1) + pts.transpose(1,0)[0], point_size=0.01)\n",
    "plot += k3d.points(neighbour_points[:,0].transpose(0,1), point_size=0.01, color=0xFF0000)\n",
    "plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-af47a53b2652d159",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "conv = PointConvolution(1,1, n_neighbours=50)\n",
    "neighbours = conv.neighbourhood(pts)\n",
    "assert((neighbours[0][:10] == [0, 764, 812, 767, 813, 1158, 768, 1165, 1159, 197]).all())\n",
    "assert((neighbours[2431][:10] == [2431, 1307, 2428, 1308, 2430, 73, 624, 2424, 2429, 2422]).all())\n",
    "### BEGIN HIDDEN TESTS\n",
    "assert((neighbours[1578][10:20] == [317, 381, 1576, 422, 1568, 1638, 1569, 1227, 1226, 1479]).all())\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-a963493c6b642c65",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "conv = PointConvolution(1,1, n_neighbours=50)\n",
    "neighbours = conv.neighbourhood(pts)\n",
    "neighbour_points = pts[:, neighbours]\n",
    "h = conv.correlation(pts, neighbour_points)\n",
    "\n",
    "np.testing.assert_approx_equal(h[0,0,0], 0.5670, significant=4)\n",
    "np.testing.assert_approx_equal(h[0,0].sum(), 7.7668, significant=4)\n",
    "np.testing.assert_approx_equal(h[579,14,8], 0.3578, significant=4)\n",
    "np.testing.assert_approx_equal(h[579,14].sum(), 8.3978, significant=4)\n",
    "\n",
    "### BEGIN HIDDEN TESTS\n",
    "np.testing.assert_approx_equal(h[2136,24,21], 0.5467, significant=4)\n",
    "np.testing.assert_approx_equal(h[2136,24].sum(), 14.2310, significant=4)\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-113dd69ff9ccfcd4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "conv = PointConvolution(1,1, n_neighbours=50)\n",
    "f = conv(torch.ones(1,2930), pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-63307b115be89890",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "colors = torch.zeros(pts.shape[0])\n",
    "colors = f.squeeze().detach()\n",
    "plot = k3d.plot()\n",
    "plot += k3d.mesh(mesh.points(), mesh.fv_indices(), attribute=colors, \n",
    "                 color_map=k3d.colormaps.matplotlib_color_maps.viridis)\n",
    "plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-432080ae998d7b3c",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "conv = PointConvolution(8,16, n_neighbours=30)\n",
    "f = conv(torch.ones(8,2930), pts)\n",
    "\n",
    "np.testing.assert_approx_equal(f.sum(), 140892496, significant=9)\n",
    "np.testing.assert_approx_equal(f[:,0].sum(), 26717.59375, significant=9)\n",
    "np.testing.assert_approx_equal(f[0,0], 1669.84960, significant=9)\n",
    "\n",
    "### BEGIN HIDDEN TESTS\n",
    "np.testing.assert_approx_equal(f[:,2458].sum(), 51558.9453, significant=9)\n",
    "np.testing.assert_approx_equal(f[12,2458], 3222.43432, significant=9)\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
