{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6c0232b",
   "metadata": {},
   "source": [
    "# Point-based Learning Methods\n",
    "For this exercise you will implement the PointNet architecture \n",
    "\n",
    "To create a dataset of point clouds you need Open3D. This can be installed via `conda install open3d`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e48b9a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import openmesh as om\n",
    "import numpy as np\n",
    "import k3d\n",
    "import matplotlib.pyplot as plt\n",
    "from jupyterplot import ProgressPlot\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.neighbors import KDTree\n",
    "\n",
    "from dataset import ModelNet10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac23c032",
   "metadata": {},
   "source": [
    "## PointNet\n",
    "The PointNet architecture you will implement in this exercise is a slightly simplified version of the one presented in the lecture. We will omit the T-Net modules for point and feature alignment.\n",
    "Your task is therefore to implement a network, that transforms each point of a point cloud individually. and then take the maximum of each feature value over all points. The number of layers and layer parameters should be the same as presented in the lecture.\n",
    "\n",
    "We will test your PointNet implementation on the ModelNet10 dataset. We will first need to download the dataset and as it contains meshes, sample it as well. This will take a couple of minutes.\n",
    "\n",
    "Make sure to upload your `best_val.ckpt` checkpoint file so that we do not have to retrain your model. If the file is not included we **cannot** give you any points for this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d19e4ee",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-d4a666afc6661622",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class PointNet(nn.Module):\n",
    "    def __init__(self, n_classes=10):\n",
    "        super().__init__()\n",
    "\n",
    "        ### BEGIN SOLUTION\n",
    "        \n",
    "        #increase dim to 64\n",
    "        self.conv1 = torch.nn.Conv1d(3, 64, 1)\n",
    "        #increase dim to 128\n",
    "        self.conv2 = torch.nn.Conv1d(64, 128, 1)\n",
    "        #increase dim to 1024\n",
    "        self.conv3 = torch.nn.Conv1d(128, 1024, 1)\n",
    "        \n",
    "        #nn with 1024 dim input, reduce finally to 10\n",
    "        self.fc1 = nn.Linear(1024, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, n_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        #batch normalization functions\n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "        self.bn3 = nn.BatchNorm1d(1024)\n",
    "        self.bn4 = nn.BatchNorm1d(512)\n",
    "        self.bn5 = nn.BatchNorm1d(256)\n",
    "        \n",
    "        ### END SOLUTION\n",
    "\n",
    "    def forward(self, x):\n",
    "        ### BEGIN SOLUTION\n",
    "        \n",
    "        #shape of x is 64(batch size)x3(dim)x1024(npts)\n",
    "                \n",
    "        #blow up dim to 1024\n",
    "        #MlP is a just a 1D conv with kernel size 1\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        \n",
    "        #shape is [64(BS), 1024(npts), 1024(feature vector for each pt)])\n",
    "        \n",
    "        #max pooling- pick the max feature for each pt in pc\n",
    "        #after max pooling shape is\n",
    "        #[64(BS), 1024(feature vec corresponding to each pt in pc), 1] \n",
    "        x = torch.max(x, 2, keepdim=True)[0]\n",
    "        \n",
    "        #reshape to 64(batchsize)x1024(feature vec wrt each pt in pc)\n",
    "        x = x.view(-1, 1024)\n",
    "\n",
    "        #add a FC NN to beat down 1024 to 10 classes\n",
    "        x = F.relu(self.bn4(self.fc1(x)))\n",
    "        x = F.relu(self.bn5(self.fc2(x)))\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        ### END SOLUTION\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af27b53b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64 # you can change the batch size depending on your memory requirements\n",
    "train_data = ModelNet10('./ModelNet10', mode=\"train\")\n",
    "val_data = ModelNet10('./ModelNet10', mode=\"val\")\n",
    "test_data = ModelNet10('./ModelNet10', mode=\"test\")\n",
    "train_loader = torch.utils.data.DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
    "val_loader = torch.utils.data.DataLoader(val_data, shuffle=False, batch_size=batch_size)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, shuffle=False, batch_size=batch_size)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    \n",
    "model = PointNet(10).to(device)\n",
    "optim = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96213ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 10\n",
    "\n",
    "pp = ProgressPlot(plot_names=[\"loss\", \"accuracy\"], line_names=[\"train\", \"val\"],\n",
    "                  x_lim=[0, n_epochs-1], y_lim=[[0,1], [0,1]])\n",
    "\n",
    "best_val_acc = -1\n",
    "\n",
    "pbar = tqdm(range(n_epochs))\n",
    "for e in pbar:\n",
    "    train_loss = 0\n",
    "    train_acc = 0\n",
    "    model.train()\n",
    "    for (x,y) in train_loader:\n",
    "        x, y = x.to(device), y.to(device)        \n",
    "        pred = model(x)\n",
    "        loss = F.cross_entropy(pred, y)\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        train_loss += loss.item()\n",
    "        train_acc += (pred.max(-1).indices == y).float().sum().item()\n",
    "    train_loss /= len(train_loader)\n",
    "    train_acc /= len(train_data)\n",
    "    \n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    val_acc = 0\n",
    "    with torch.no_grad():\n",
    "        for (x,y) in val_loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            pred = model(x)\n",
    "            loss = F.cross_entropy(pred, y)\n",
    "            val_loss += loss.item()\n",
    "            val_acc += (pred.max(-1).indices == y).float().sum().item()\n",
    "        val_loss /= len(val_loader)\n",
    "        val_acc /= len(val_data)\n",
    "        if val_acc > best_val_acc:\n",
    "            torch.save({\n",
    "            'epoch': e,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optim_state_dict': optim.state_dict(),\n",
    "            'val_acc': val_acc,\n",
    "            }, \"best_val.ckpt\")\n",
    "    \n",
    "    pp.update([[train_loss, val_loss], [train_acc, val_acc]])\n",
    "    pbar.set_description(f\"train loss: {train_loss:.4f}, train acc.: {train_acc:.4f}\")\n",
    "pp.finalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f16ba9",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-2a733f240a6dade1",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "checkpoint = torch.load(\"best_val.ckpt\")\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval()\n",
    "test_acc = 0\n",
    "with torch.no_grad():\n",
    "    for (x,y) in tqdm(test_loader):\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            pred = model(x)\n",
    "            test_acc += (pred.max(-1).indices == y).float().sum().item()\n",
    "test_acc /= len(test_data)\n",
    "print(f\"test acc.: {test_acc}\")\n",
    "assert test_acc >= 0.7"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
